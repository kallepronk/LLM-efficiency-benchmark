name: llm-efficiency-benchmark
services:
    vllm-openai:
        runtime: nvidia
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities:
                              - gpu
        volumes:
            - ~/.cache/huggingface:/root/.cache/huggingface
        environment:
            - HUGGING_FACE_HUB_TOKEN=<secret>
        ports:
            - 8000:8000
        ipc: host
        image: vllm/vllm-openai:latest
        command: --model mistralai/Mistral-7B-v0.1