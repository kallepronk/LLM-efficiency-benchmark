{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = os.path.abspath(os.getcwd()+'/..')\n",
    "\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from benchmark.runs.run import Run\n",
    "from benchmark.runs.warmup import Warmup\n",
    "from benchmark.runs.vllm import vLLMRun\n",
    "from benchmark.main import Benchmark\n",
    "from benchmark.dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1428e108fe4170d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# With encoding\n",
    "\n",
    "async def load_test(model: str, dataset: Dataset, name: str):\n",
    "\n",
    "    # Configure runs\n",
    "    warmup: Run = vLLMRun(model=model, dataset=dataset, passes=500)\n",
    "\n",
    "    run1: Run = vLLMRun(model=model, dataset=dataset, passes=1)\n",
    "    run5: Run = vLLMRun(model=model, dataset=dataset, passes=5)\n",
    "    run10: Run = vLLMRun(model=model, dataset=dataset, passes=10)\n",
    "    run20: Run = vLLMRun(model=model, dataset=dataset, passes=20)\n",
    "    run40: Run = vLLMRun(model=model, dataset=dataset, passes=40)\n",
    "    run100: Run = vLLMRun(model=model, dataset=dataset, passes=100)\n",
    "    run200: Run = vLLMRun(model=model, dataset=dataset, passes=200)\n",
    "    run500: Run = vLLMRun(model=model, dataset=dataset, passes=500)\n",
    "    run1000: Run = vLLMRun(model=model, dataset=dataset, passes=1000)\n",
    "    run2000: Run = vLLMRun(model=model, dataset=dataset, passes=2000)\n",
    "    run5000: Run = vLLMRun(model=model, dataset=dataset, passes=5000)\n",
    "\n",
    "    # Configure classes\n",
    "    benchmark = Benchmark(name=name, runs=[warmup, run1, run5, run10, run20, run40, run100, run200, run500, run1000, run2000, run5000])\n",
    "\n",
    "    await benchmark.run_async()\n",
    "\n",
    "    print(benchmark.collect_results())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b8d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# With encoding\n",
    "\n",
    "async def request_rate_test(model: str, dataset: Dataset, name: str):\n",
    "\n",
    "    # Configure runs\n",
    "    warmup: Run = vLLMRun(model=model, dataset=dataset, passes=500)\n",
    "    run1: Run = vLLMRun(model=model, dataset=dataset, passes=500, request_rate=1)\n",
    "    run50: Run = vLLMRun(model=model, dataset=dataset, passes=500, request_rate=50)\n",
    "    run100: Run = vLLMRun(model=model, dataset=dataset, passes=500, request_rate=100)\n",
    "    run200: Run = vLLMRun(model=model, dataset=dataset, passes=500, request_rate=200)\n",
    "    run400: Run = vLLMRun(model=model, dataset=dataset, passes=500, request_rate=400)\n",
    "    run500: Run = vLLMRun(model=model, dataset=dataset, passes=500, request_rate=500)\n",
    "    run1000: Run = vLLMRun(model=model, dataset=dataset, passes=500, request_rate=1000)\n",
    "\n",
    "\n",
    "    # Configure classes\n",
    "    benchmark = Benchmark(name=name, runs=[warmup, run1, run50, run100, run200, run400, run500, run1000])\n",
    "\n",
    "    await benchmark.run_async()\n",
    "\n",
    "    print(benchmark.collect_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31483749",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: Dataset = Dataset(name=\"Rowan/hellaswag\", split=\"train\", column=\"ctx\")\n",
    "#await load_test(model=\"EleutherAI/pythia-70m\", dataset=dataset, name=\"pythia-70m\")\n",
    "#await load_test(model=\"EleutherAI/pythia-160m\", dataset=dataset, name=\"pythia-160m\")\n",
    "#await load_test(model=\"EleutherAI/pythia-410m\", dataset=dataset, name=\"pythia-410m\")\n",
    "#await load_test(model=\"EleutherAI/pythia-1b\", dataset=dataset, name=\"pythia-1b\")\n",
    "#await load_test(model=\"EleutherAI/pythia-1.4b\", dataset=dataset, name=\"pythia-1.4b\")\n",
    "await load_test(model=\"EleutherAI/pythia-2.8b\", dataset=dataset, name=\"pythia-2.8b\")\n",
    "await load_test(model=\"EleutherAI/pythia-6.9b\", dataset=dataset, name=\"pythia-6.9b\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124254a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: Dataset = Dataset(name=\"Rowan/hellaswag\", split=\"train\", column=\"ctx\")\n",
    "#await load_test(model=\"databricks/dolly-v2-3b\", dataset=dataset, name=\"Dolly V2\")\n",
    "#await load_test(model=\"bigscience/bloom-3b\", dataset=dataset, name=\"Bloom\")\n",
    "#await load_test(model=\"togethercomputer/RedPajama-INCITE-Base-3B-v1\", dataset=dataset, name=\"redPajama\")\n",
    "await load_test(model=\"openlm-research/open_llama_3b_v2\", dataset=dataset, name=\"open Llama\")\n",
    "#await load_test(model=\"EleutherAI/pythia-2.8b\", dataset=dataset, name=\"pythia-2.8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df038b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: Dataset = Dataset(name=\"Rowan/hellaswag\", split=\"train\", column=\"ctx\")\n",
    "#await request_rate_test(model=\"EleutherAI/pythia-70m\", dataset=dataset, name=\"rr_pythia-70m\")\n",
    "#await request_rate_test(model=\"EleutherAI/pythia-160m\", dataset=dataset, name=\"rr_pythia-160m\")\n",
    "#await request_rate_test(model=\"EleutherAI/pythia-410m\", dataset=dataset, name=\"rr_pythia-410m\")\n",
    "#await request_rate_test(model=\"EleutherAI/pythia-1b\", dataset=dataset, name=\"rr_pythia-1b\")\n",
    "#await request_rate_test(model=\"EleutherAI/pythia-1.4b\", dataset=dataset, name=\"rr_pythia-1.4b\")\n",
    "await request_rate_test(model=\"EleutherAI/pythia-2.8b\", dataset=dataset, name=\"rr_pythia-2.8b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cbd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "# Graph data\n",
    "\n",
    "\n",
    "def data_from_json(file: str, type: str) -> [float]:\n",
    "    data = json.load(open(file))\n",
    "\n",
    "    return [data[\"runs\"][0][type], data[\"runs\"][1][type], data[\"runs\"][2][type], data[\"runs\"][3][type], data[\"runs\"][4][type], data[\"runs\"][5][type], data[\"runs\"][6][type], data[\"runs\"][7][type], data[\"runs\"][8][type], data[\"runs\"][9][type], data[\"runs\"][10][type], data[\"runs\"][11][type]]\n",
    "\n",
    "\n",
    "x = np.arange(12)\n",
    "\n",
    "results1 = data_from_json(\"results_vLLM-20241218-121854.json\", \"gpu_energy\")\n",
    "#  results2 = data_from_json(\"resultsV3.json\", \"gpu_energy\")\n",
    "#   results3 = data_from_json(\"results_with_encoding-20241203-174821.json\", \"gpu_energy\")\n",
    "#   results4 = data_from_json(\"results_with_encoding-20241203-195144.json\", \"gpu_energy\")\n",
    "#   results5 = data_from_json(\"results_with_encoding-20241203-200703.json\", \"gpu_energy\")\n",
    "\n",
    "ram_energy1 = data_from_json(\"results_vLLM-20241218-121854.json\", \"ram_energy\")\n",
    "#   ram_energy2 = data_from_json(\"resultsV3.json\", \"ram_energy\")\n",
    "#   ram_energy3 = data_from_json(\"results_with_encoding-20241203-174821.json\", \"ram_energy\")\n",
    "#   ram_energy4 = data_from_json(\"results_with_encoding-20241203-195144.json\", \"ram_energy\")\n",
    "#   ram_energy5 = data_from_json(\"results_with_encoding-20241203-200703.json\", \"ram_energy\")\n",
    "\n",
    "cpu_energy1 = data_from_json(\"results_vLLM-20241218-121854.json\", \"cpu_energy\")\n",
    "#   cpu_energy2 = data_from_json(\"resultsV3.json\", \"cpu_energy\")\n",
    "#   cpu_energy3 = data_from_json(\"results_with_encoding-20241203-174821.json\", \"cpu_energy\")\n",
    "#   cpu_energy4 = data_from_json(\"results_with_encoding-20241203-195144.json\", \"cpu_energy\")\n",
    "#   cpu_energy5 = data_from_json(\"results_with_encoding-20241203-200703.json\", \"cpu_energy\")\n",
    "\n",
    "duration1 = data_from_json(\"results_vLLM-20241218-121854.json\", \"duration\")\n",
    "#   duration2 = data_from_json(\"resultsV3.json\", \"duration\")\n",
    "#   duration3 = data_from_json(\"results_with_encoding-20241203-174821.json\", \"duration\")\n",
    "#   duration4 = data_from_json(\"results_with_encoding-20241203-195144.json\", \"duration\")\n",
    "#   duration5 = data_from_json(\"results_with_encoding-20241203-200703.json\", \"duration\")\n",
    "\n",
    "\n",
    "x_values = [1, 5, 10, 20, 40, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "gpu = np.divide(np.mean([results1], axis=0), x_values)\n",
    "ram = np.divide(np.mean([ram_energy1], axis=0), x_values)\n",
    "cpu = np.divide(np.mean([cpu_energy1], axis=0), x_values)\n",
    "time = np.mean([duration1], axis=0)\n",
    "\n",
    "x_labels = [\"1\", \"5\", \"10\", \"20\", \"40\", \"100\", \"200\", \"500\", \"1000\", \"2000\", \"5000\", \"10000\"]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(x-0.2, gpu, color=\"g\", align=\"center\", width=0.2)\n",
    "plt.bar(x+0.2, ram, color=\"r\", align=\"center\", width=0.2)\n",
    "plt.bar(x, cpu, color=\"b\", align=\"center\", width=0.2)\n",
    "\n",
    "plt.xlabel(\"Passes\")\n",
    "plt.ylabel(\"GPU Energy\")\n",
    "plt.title(\"GPU per energy amount\")\n",
    "plt.xticks(x, x_labels)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(x, time)\n",
    "plt.xticks(x, x_labels)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-efficiency-benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
